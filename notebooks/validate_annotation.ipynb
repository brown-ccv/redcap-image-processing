{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Validation\n",
    "\n",
    "This notebook attempts to validate that a single annotation is overlayed with the area annotation.\n",
    "\n",
    "NOTE: The data processing done is specific to the data stored on the validation server.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in config file\n",
    "config_file = '/Users/mslivins/Projects/redcap-image-processing/envs/validation.env'\n",
    "config = utils.read_env(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record ID to test\n",
    "test_record = '95'\n",
    "data = {\n",
    "    'token': config['API_TOKEN'],\n",
    "    'content': 'record',\n",
    "    'action': 'export',\n",
    "    'format': 'csv',\n",
    "    'type': 'flat',\n",
    "    'csvDelimiter': '',\n",
    "    'records[0]': test_record,\n",
    "    'rawOrLabel': 'raw',\n",
    "    'rawOrLabelHeaders': 'raw',\n",
    "    'exportCheckboxLabel': 'false',\n",
    "    'exportSurveyFields': 'false',\n",
    "    'exportDataAccessGroups': 'false',\n",
    "    'returnFormat': 'csv'}\n",
    "# POST request\n",
    "r = utils.post_request(config['API_URL'], data)\n",
    "print('HTTP Status: ' + str(r.status_code))\n",
    "assert str(r.status_code) == '200', \"Need 200 successful response\"\n",
    "# Convert CSV request to dict records\n",
    "records = utils.records_to_dict(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Process annotation data.\n",
    "\n",
    "NOTE: Assume there is only one annotation area per set of individual annotated scars.\n",
    "'''\n",
    "# Process annotation data\n",
    "for record_id, record in records.items():\n",
    "    # Get all annotation keys\n",
    "    annot_keys = [key for key in list(record.keys()) if 'annotate' in key]\n",
    "    annots_dict = {}\n",
    "    for annot_key in annot_keys:\n",
    "        if record[annot_key] != '':\n",
    "            # Convert string JSON into dictionary\n",
    "            annot_dict = json.loads(record[annot_key])\n",
    "            # Add image from url\n",
    "            annot_url = annot_dict['markers'][0]['drawingImgUrl']\n",
    "            annot_img = Image.open(urllib.request.urlopen(annot_url))\n",
    "            annot_dict['annot_img'] = annot_img\n",
    "            annots_dict[annot_key] = annot_dict\n",
    "# Get area annotation image\n",
    "test_area_name = 'bl_c_img_flf_annotate_all'\n",
    "area_img_dict = annots_dict[test_area_name]\n",
    "area_img = area_img_dict['annot_img']\n",
    "# Get single annotation image\n",
    "test_single_name = 'bl_c_flf1_annotate_scar'\n",
    "sing_img_dict = annots_dict[test_single_name]\n",
    "sing_img = sing_img_dict['annot_img']\n",
    "# Create blank base to overlay annotations onto\n",
    "orig_size = (area_img_dict['width'], area_img_dict['height'])\n",
    "base_img = Image.new('RGB', orig_size)\n",
    "# Align and overlay filled area annotation\n",
    "left_align = area_img_dict['markers'][0]['left']\n",
    "top_align = area_img_dict['markers'][0]['top']\n",
    "area_overlay = base_img.copy()\n",
    "area_overlay.paste(area_img, (left_align, top_align), area_img)\n",
    "# Fill in overlay with a color other than black or white (e.g., magenta=255,0,255)\n",
    "ImageDraw.floodfill(area_overlay, xy=(0, 0), value=(255, 0, 255), thresh=200)\n",
    "# Make everything not magenta white\n",
    "np_area = np.array(area_overlay)\n",
    "np_area[(np_area[:, :, 0:3] != [255,0,255]).any(2)] = [255, 255, 255]\n",
    "# Revert everthing else to black\n",
    "np_area[(np_area[:, :, 0:3] == [255,0,255]).all(2)] = [0, 0, 0]\n",
    "# Convert to bool area and compress to 1 image channel\n",
    "np_area = np.array(np_area, dtype=bool).sum(axis=2, dtype=bool)\n",
    "# Align and overlay single annotation\n",
    "left_align = sing_img_dict['markers'][0]['left']\n",
    "top_align = sing_img_dict['markers'][0]['top']\n",
    "sing_overlay = base_img.copy()\n",
    "sing_overlay.paste(sing_img, (left_align, top_align), sing_img)\n",
    "np_sing = np.array(sing_overlay, dtype=bool).sum(axis=2, dtype=bool)\n",
    "# If the intersection of the single and area annotation is not equal to the \n",
    "# annotation area then there exists a pixel in the single annotation that is \n",
    "# outside the annotation area\n",
    "display(utils.bytes_to_img(np_area))\n",
    "display(utils.bytes_to_img(np_sing))\n",
    "display(utils.bytes_to_img(np.logical_or(np_sing, np_area)))\n",
    "np_union = np.logical_or(np_sing, np_area)\n",
    "np.array_equal(np_union, np_area)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fb2aa870e587b214a07e5b8985754724f870bf26e60f412e0f205dee22244b9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('rdc-img-val')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
