{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in config file\n",
    "config_file = '/Users/mslivins/Projects/redcap-image-processing/src/validation.env'\n",
    "config = utils.read_env(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Status: 200\n"
     ]
    }
   ],
   "source": [
    "# Request single record\n",
    "# test_record = '94'  # pass: all 3 singles are within 1 area\n",
    "test_record = '95'  # fail: 1 single is not within 1 area\n",
    "data = {\n",
    "    'token': config['API_TOKEN'],\n",
    "    'content': 'record',\n",
    "    'action': 'export',\n",
    "    'format': 'csv',\n",
    "    'type': 'flat',\n",
    "    'csvDelimiter': '',\n",
    "    'records[0]': test_record,\n",
    "    'rawOrLabel': 'raw',\n",
    "    'rawOrLabelHeaders': 'raw',\n",
    "    'exportCheckboxLabel': 'false',\n",
    "    'exportSurveyFields': 'false',\n",
    "    'exportDataAccessGroups': 'false',\n",
    "    'returnFormat': 'csv'\n",
    "}\n",
    "r = utils.post_request(config['API_URL'], data)\n",
    "print('HTTP Status: ' + str(r.status_code))\n",
    "assert str(r.status_code) == '200', \"Need 200 successful response\"\n",
    "\n",
    "# Convert CSV request to dict records\n",
    "records = utils.records_to_dict(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAOyAQAAAABY1y57AAAEF0lEQVR4nO3aMVLcMBTGcS1LQiaTCVtSMGGPkDIdPkqOwAkSH4WjuMhBXFI6GQpgQpQikJVkSX5Pkme2+P+qtSU+P7S27LVtDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACgzLm100q51lr7u3nwlX3RNw7evgbPBmRTmWz/f3o+9VtO6oKvDx+3fV2U78w6Rr+truYv7sKF31Y1zm+e3CXrV1lV83tvadPXZHm8UZ4NdE3N74Jlf6Brkm+C5bOKLM/WhoYmudezXGsf3A6le93mT2Slt9+VjvO36Ob6wjQnIjIU4X5XVnO0YuPvd0XjvE2dQNyBLkq2yRYnrmQ0tummoS75Q7ppX5d8k25yvsKCcY4eJC+ck2FBzR8zbSfRj1KfM22b6Eeh3GC4efqa83/RVyRfZlu7iuS9+i+EUtPcbLZT1/w237wrT75Y7lKY/FXaUb0/p2dQY4wxP3evn7Q1Z2bQgDY5M4NWJt+IeyrHOT9pmIpx/iTvqkwe10rWXG3qksUHoDp5XCtZfphok/OTfk3yuFayajBUyfI5Q5u8Wy15v1pyp0rWzHULpxNjTM05RU6RrJzKj6JmZRGta55WSz5QJJ8udylMFhlLksObOwuOYpx3qyWLDCXJe9021htnhe/53z7/HLqvV7NiapRM/M7tnmPYn0X/nXPh3rhm56aYPFlbQ+OanXuu8mTR9DyVJIuMJcmi6Xk4fJQfKVejoFPl3cs09zCVJ++VW2lbs/vbuW2ye19antwJ+rgPJ9rWPK2WPBb9leRc1Tv95UeK5JTipolHQ1KCt/Gm4+zdChInq0toWrP3AEecLJn4vad4TWueipIlE/9YlCwxuAviI+V8Wu7jhbWs2T9KWyZ77wLIk3fa7YiTp+Uud2XJD8tdxrJktZbJg7ck3p+Tz4tTWeKal27Dz0464uTlk1Wwbfk475Y63Jcm/1rqMJUm26V5dCxNNo+7fPvgL2pu7y08pgmiNEeK7bKt+Q3lZWf/qnfV7nON4TGqSs6OczgZqpKzbxRONcnhjuW5DZZ1N5VzX2GYpKs5c2KZzVi65MwcPft2dcnPio0qz1Z9skVwBs4KXwOMv5hljFHX/JhsuQ1XaJ/+J/e7WZA2OTWT2tk/r73eSM2kT/HVGufxL3CYdVS/ZZEYjnmO+uorPt9lDiG5q9hgRI4T/RXjnXBlwbtqkeuw8BxoTNFVbjdf9SPSreQ9xnnRsZSSK/MuXNFkzzAmMuFNsV5N3uqMhhT9Tun8xfTUqubPHWO7YP+d6r5hsPegaWwaDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABy1vxs6zW+rnqV0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=710x946 at 0x7FAE087E7370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAOyAQAAAABY1y57AAAB7UlEQVR4nO3aPW4TURiG0ThBQIGwSwqEXFKmpCJeCkvxMljOLGWWkJICEdo0SN8b6UUzcE79zaOrK3nG83NzAwAAAAAAAAD8d86zsdu8fMkPGVpnY/maD7Xy7RIfMvRmuoINld/Xyh9r5c/xEVPLcC5e82Fajt1NB+M198pva+VftfK7WvlcK39JDxhbp4Pxmmvl+U8wLb/gijw0Pe/na3iqlV/Xyqda+Wet/KFWvoTzc+t4Ml1zrRxcX8Ny78c9vr7Gi3hVK89PG2l5/J8gLo//E8TlU608PyGl5XOt/KNWDoTlS638WCv3rPPRcM29ciArH2rl8W1mXg5spbyJC+xmdmOPZfus/Cfzu8HtrFn5ufGDr7icUN5ief50YztrVn7uvlZOKP+dcmYJZve4GxspR+8GN7LmjZQjyW3KLndDWVlZeTvlyOEaDO9xN/ZYzizB7B53Q/nl1lr5WzCb7cYpmk7cB7PZmoMX6aHkaU+m94yx+G3WtVXufSxafA/7PRsPfKqVj7Xy3VJLP9bKD9dW+bi2yslXJ6GvtfJxaZUPve14qJXnX7mmimdSAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPhn/Aag4yWSOgPr0QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=710x946 at 0x7FADB8B114F0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAOyAQAAAABY1y57AAAFgklEQVR4nO3dP5LcRBjGYc0OYIqiGIUEFDsh4YZErI7iI+wJQMcg9FEUcBCFDgXlALswIsCu7ZZare9t6XNpyr8nmj8973zbK7U0kkpdVQAAAAAAAAAAAAAA4LNztTW705Mb/SNGva2ZXvPJLfmukz9i9MJawYGSv3NL/sEt+Sf5E1adsZ1c88maLDtbG8o1+yV/7Zb8r1vyt27JV7fkn9UPmPXWhnLNbsn2VVBNLtgiG1nHfb2G0S35K7fk2i35H7fk792SG7G9XW9uqdbslixsX8Vkv5XbvH2Vi/jCLdk+bKjJ5n0COdm8TyAn127J9gFJTb66Jf/tliwQkxu35MEt2U9vbyrW7Jcs0JJPbsnmn5l6suAoyYfYwB6mN24xmX4meYn91+BxaiY5ZD7wJScrSD5isv3oxnFqJjn04JasIPnTJGs6oe0t9sZBkqVzgwep+SDJEuVnyk32Bskkk0zycZIlp1ZofIu9cYvJmk5oe4u9QXK53i35pdBW641aaq14ENpqNQsn0kXK0R6N3zFGx2uzWq9kv4tFHc/D/q41F/zolnxxSz53btGDW/Jj65V86b2SlatORL+4JV86r+STX3c8uiXbr3JVOY6kAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA+OxdxnFwyh3HcRTmIDK6Hz9odw4+fwyedYgyi0vK84RX7yezam28s1RwO5Vzuy0q9mIM9PF722qOppOc3AxsUz9/+S58NsZVbqr5m+iZdIfJvKiXZx29pebp/dvijt6S/DR5vtt9d87jVLdL7uMsdxyjGxyVLnWn1Jxw0XJX2s+/Jr+uLUwLIhJdMV3uympOVlzFy11RP5+XNiBhRxclL89CGMSV9EbmFuHdtuTMHQ6v25Kflt8K/oUF/ZxcST4INoYFNecmHb9LPrR6yLx3Sj40ynVGmKfXnP9EuyE5PwN7syH5Kn/CaGmYm412cs0rE1HV5cnm26LKyS+tDeXleWUe1z/rj4/Umu2TLKjJ9nvEqslP5pZiP+cHjWpDPwv3RD3KTJ3K3uZRZqHqvZL95iLJD/pbknuvZKkzpGTlvtJacu2WfHVLbqRkZayzTAtevk2xE5LFofwQNYtF7F3z4Jb8TEgWZrkXk036kmTx5vyH6OfaLdmkK0m+at9xiDkyfsv/9vnfc3O/moWh0TLwB4d7jrA8m/66YMd955qDg2L2ZLWGnWsOjrnak03D81CSbNKXJJuG5+75oX1Nue8NjTYevVwWrqb25Kv4LfvWHP523jc5PC5tT24MbcKTE/vWPLgl90Wfsmyr2qC9fU2xbFLCNHNvWEqIvnzXfo4OBZmT5RJ2rTk6gWNOtgz80Vm8XWseipItA39flGzRhU/Ma8plWG8The1Zc7yW7pkcXQtgT67V7zEnD+tNXpclGybr6cuSZXsmd9Ez8/K8eL54Kctc89ph+NlGx5y8vrGafLe9n+u1Bm9Kk/9aazCUJo9r42hfmly9rfPvd/FT5fDeymmaSZSypoxN9t38F+VlR/9N16q9yb05XUel5Gw/TwdDKTl7ReGwJTk7p+2ryXPtoHLuXzhN0mrObFhmI5aWnBmjZ/9dLfm98KXi1qpdfGfrdHnTywDTF2ZVVSXX/HbxnVfTF9Sz/4vL3SxITV4aScfZH6/ubyyNpO/SLysu6X9gN2soX2Wx0B3zHHnvKz3eZVYhu/tUZyTWE32P8bXxxYJr1RL7YdNtYFUV7eU285f+SDQruY5xXnQqpWTPvJm+sMuSUVWJAW9Itdrlqs5kSNHvlCZ+ujy0yuKxo98vOL6mut0xODrR1O8aDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABzaf2968wBnUVA3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=710x946 at 0x7FADA8EAC160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process annotation data\n",
    "# NOTE: We assume there is only one annotation area per set of individual \n",
    "# annotated scars.\n",
    "# TODO: this will need to change to handle multiple annotation areas\n",
    "for record_id, record in records.items():\n",
    "    # Get all annotation keys\n",
    "    annot_keys = [key for key in list(record.keys()) if 'annotate' in key]\n",
    "    annots_dict = {}\n",
    "    for annot_key in annot_keys:\n",
    "        if record[annot_key] != '':\n",
    "            # Convert string JSON into dictionary\n",
    "            annot_dict = json.loads(record[annot_key])\n",
    "            # Add image from url\n",
    "            annot_url = annot_dict['markers'][0]['drawingImgUrl']\n",
    "            annot_img = Image.open(urllib.request.urlopen(annot_url))\n",
    "            annot_dict['annot_img'] = annot_img\n",
    "            annots_dict[annot_key] = annot_dict\n",
    "\n",
    "# pprint(annots_dict)\n",
    "\n",
    "# TODO: need to recreate annotations based on original image size\n",
    "# Get area annotation image\n",
    "test_area_name = 'bl_c_img_flf_annotate_all'\n",
    "area_img_dict = annots_dict[test_area_name]\n",
    "area_img = area_img_dict['annot_img']\n",
    "\n",
    "# Get single annotation image\n",
    "test_single_name = 'bl_c_flf1_annotate_scar'\n",
    "sing_img_dict = annots_dict[test_single_name]\n",
    "sing_img = sing_img_dict['annot_img']\n",
    "\n",
    "# Create blank base to overlay annotations onto\n",
    "orig_size = (area_img_dict['width'], area_img_dict['height'])\n",
    "base_img = Image.new('RGB', orig_size)\n",
    "\n",
    "# Align and overlay filled area annotation\n",
    "left_align = area_img_dict['markers'][0]['left']\n",
    "top_align = area_img_dict['markers'][0]['top']\n",
    "area_overlay = base_img.copy()\n",
    "area_overlay.paste(area_img, (left_align, top_align), area_img)\n",
    "# Fill in overlay with a color other than black or white (e.g., magenta=255,0,255)\n",
    "ImageDraw.floodfill(area_overlay, xy=(0, 0), value=(255, 0, 255), thresh=200)\n",
    "# Make everything not magenta white\n",
    "np_area = np.array(area_overlay)\n",
    "np_area[(np_area[:, :, 0:3] != [255,0,255]).any(2)] = [255, 255, 255]\n",
    "# Revert everthing else to black\n",
    "np_area[(np_area[:, :, 0:3] == [255,0,255]).all(2)] = [0, 0, 0]\n",
    "# Convert to bool area and compress to 1 image channel\n",
    "np_area = np.array(np_area, dtype=bool).sum(axis=2, dtype=bool)\n",
    "\n",
    "# Align and overlay single annotation\n",
    "left_align = sing_img_dict['markers'][0]['left']\n",
    "top_align = sing_img_dict['markers'][0]['top']\n",
    "sing_overlay = base_img.copy()\n",
    "sing_overlay.paste(sing_img, (left_align, top_align), sing_img)\n",
    "np_sing = np.array(sing_overlay, dtype=bool).sum(axis=2, dtype=bool)\n",
    "\n",
    "# If the intersection of the single and area annotation is not equal to the \n",
    "# annotation area then there exists a pixel in the single annotation that is \n",
    "# outside the annotation area\n",
    "display(utils.bytes_to_img(np_area))\n",
    "display(utils.bytes_to_img(np_sing))\n",
    "display(utils.bytes_to_img(np.logical_or(np_sing, np_area)))\n",
    "np_union = np.logical_or(np_sing, np_area)\n",
    "np.array_equal(np_union, np_area)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fb2aa870e587b214a07e5b8985754724f870bf26e60f412e0f205dee22244b9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('rdc-img-val')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
